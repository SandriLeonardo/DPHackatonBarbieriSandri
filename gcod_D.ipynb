{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-30T15:33:52.933298Z",
     "iopub.status.busy": "2025-05-30T15:33:52.932776Z",
     "iopub.status.idle": "2025-05-30T15:33:55.986952Z",
     "shell.execute_reply": "2025-05-30T15:33:55.986255Z",
     "shell.execute_reply.started": "2025-05-30T15:33:52.933275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:33:55.988454Z",
     "iopub.status.busy": "2025-05-30T15:33:55.988217Z",
     "iopub.status.idle": "2025-05-30T15:34:04.372644Z",
     "shell.execute_reply": "2025-05-30T15:34:04.372065Z",
     "shell.execute_reply.started": "2025-05-30T15:33:55.988428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import dropout_edge\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.373584Z",
     "iopub.status.busy": "2025-05-30T15:34:04.373274Z",
     "iopub.status.idle": "2025-05-30T15:34:04.920784Z",
     "shell.execute_reply": "2025-05-30T15:34:04.920150Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.373567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "helper_scripts_path = '/kaggle/input/myhackatonhelperscripts'\n",
    "\n",
    "if os.path.exists(helper_scripts_path):\n",
    "    # Add this path to the beginning of Python's search list\n",
    "    sys.path.insert(0, helper_scripts_path)\n",
    "    print(f\"Successfully added '{helper_scripts_path}' to sys.path.\")\n",
    "    print(f\"Contents of '{helper_scripts_path}': {os.listdir(helper_scripts_path)}\") # Verify\n",
    "else:\n",
    "    print(f\"WARNING: Helper scripts path not found: {helper_scripts_path}\")\n",
    "    print(\"Please ensure 'myhackathonhelperscripts' dataset is correctly added to the notebook.\")\n",
    "\n",
    "# Start import of utils modules\n",
    "try:\n",
    "    from preprocessor import MultiDatasetLoader\n",
    "    from utils import set_seed\n",
    "    # from conv import GINConv as OriginalRepoGINConv\n",
    "    from models_EDandBatch_norm import GNN\n",
    "    print(\"Successfully imported modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing module: {e}\")\n",
    "    print(\"Please check that the .py files exist directly under the helper_scripts_path and have no syntax errors.\")\n",
    "    # print(\"Current sys.path:\", sys.path)\n",
    "\n",
    "# Set the random seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.922626Z",
     "iopub.status.busy": "2025-05-30T15:34:04.922245Z",
     "iopub.status.idle": "2025-05-30T15:34:04.926469Z",
     "shell.execute_reply": "2025-05-30T15:34:04.925674Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.922606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_zeros(data):\n",
    "    data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.927344Z",
     "iopub.status.busy": "2025-05-30T15:34:04.927135Z",
     "iopub.status.idle": "2025-05-30T15:34:04.941009Z",
     "shell.execute_reply": "2025-05-30T15:34:04.940365Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.927328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# In the cell with 'def train(...)'\n",
    "\n",
    "def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch,\n",
    "          args_namespace, u_values_global, current_baseline_mode, scheduler=None): # Added new params\n",
    "    model.train()\n",
    "    total_loss_accum = 0.0 \n",
    "    correct_preds = 0 \n",
    "    total_samples_processed = 0 \n",
    "\n",
    "    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        if current_baseline_mode == 4: # GCOD specific logic\n",
    "            # Corrected line for batch_indices:\n",
    "            batch_indices = data.original_idx.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            # Ensure u_values_global is on the correct device if batch_indices are used directly\n",
    "            # If u_values_global is on CPU, then indices should be CPU too before indexing.\n",
    "            # Assuming u_values_global is already on the same device as model/data or CPU (handled by .to(device) below)\n",
    "            if u_values_global.device != device: # If u_values_global is on CPU and device is GPU\n",
    "                 u_batch_cpu = u_values_global[batch_indices.cpu()].clone().detach()\n",
    "                 u_batch = u_batch_cpu.to(device).requires_grad_(True)\n",
    "            else: # If u_values_global is already on the target device\n",
    "                 u_batch = u_values_global[batch_indices].clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "            # Using the 'output' from the main model pass for u_optimization as well.\n",
    "            # Detach it to prevent gradients from L2 flowing back to model parameters during u-opt.\n",
    "            output_for_u_optim = output.detach()\n",
    "\n",
    "            for _ in range(args_namespace.gcod_T_u):\n",
    "                # Corrected condition for checking gradient:\n",
    "                if u_batch.grad is not None:\n",
    "                    u_batch.grad.zero_()\n",
    "                \n",
    "                L2_for_u = criterion.compute_L2(output_for_u_optim, data.y, u_batch)\n",
    "                \n",
    "                L2_for_u.backward() \n",
    "                with torch.no_grad():\n",
    "                    u_batch.data -= args_namespace.gcod_lr_u * u_batch.grad.data\n",
    "                    u_batch.data.clamp_(0, 1) \n",
    "            \n",
    "            u_batch_optimized = u_batch.detach() \n",
    "\n",
    "            pred_for_acc = output.argmax(dim=1)\n",
    "            if data.y.size(0) > 0:\n",
    "                batch_accuracy = (pred_for_acc == data.y).sum().item() / data.y.size(0)\n",
    "            else:\n",
    "                batch_accuracy = 0.0\n",
    "\n",
    "            loss_theta_components = criterion(output, data.y, u_batch_optimized, batch_accuracy)\n",
    "            actual_loss_for_bp = loss_theta_components[0] \n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Ensure batch_indices are on the same device as u_values_global for assignment\n",
    "                if u_values_global.device != device:\n",
    "                    u_values_global[batch_indices.cpu()] = u_batch_optimized.cpu()\n",
    "                else:\n",
    "                    u_values_global[batch_indices] = u_batch_optimized\n",
    "        \n",
    "        else: \n",
    "            actual_loss_for_bp = criterion(output, data.y)\n",
    "        \n",
    "        try:\n",
    "            actual_loss_for_bp.backward()\n",
    "            optimizer.step()\n",
    "            # Step OneCycleLR scheduler after each batch\n",
    "            if scheduler is not None and args.scheduler_type == 'OneCycleLR':\n",
    "                scheduler.step()\n",
    "        except IndexError as e:\n",
    "            edge_max_val = data.edge_index.max().item() if data.edge_index.numel() > 0 else 'N/A'\n",
    "            print(f\"Error in batch with {data.num_nodes} nodes, edge_max={edge_max_val}\")\n",
    "            print(f\"Batch info: x.shape={data.x.shape}, edge_index.shape={data.edge_index.shape}\")\n",
    "            if current_baseline_mode == 4:\n",
    "                print(f\"GCOD context: u_batch_optimized shape: {u_batch_optimized.shape if 'u_batch_optimized' in locals() else 'N/A'}\")\n",
    "            raise e\n",
    "        \n",
    "        total_loss_accum += actual_loss_for_bp.item() \n",
    "        \n",
    "        pred_final = output.argmax(dim=1)\n",
    "        correct_preds += (pred_final == data.y).sum().item()\n",
    "        total_samples_processed += data.y.size(0)\n",
    "\n",
    "    if save_checkpoints: \n",
    "        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_file)\n",
    "        print(f\"Checkpoint saved at {checkpoint_file}\")\n",
    "\n",
    "    avg_loss = total_loss_accum / len(data_loader) if len(data_loader) > 0 else 0.0\n",
    "    accuracy = correct_preds / total_samples_processed if total_samples_processed > 0 else 0.0\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.941724Z",
     "iopub.status.busy": "2025-05-30T15:34:04.941557Z",
     "iopub.status.idle": "2025-05-30T15:34:04.953008Z",
     "shell.execute_reply": "2025-05-30T15:34:04.952334Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.941710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CELL 7 (Corrected)\n",
    "# def evaluate(data_loader, model, criterion, device, calculate_accuracy=False): # Original\n",
    "def evaluate(data_loader, model, criterion, device, calculate_accuracy=False, args_namespace=None, u_values_global_eval=None): # Added args_namespace and u_values for eval if needed\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions_list = [] # Renamed\n",
    "    total_loss_val = 0 # Renamed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "\n",
    "            if calculate_accuracy:\n",
    "                correct += (pred == data.y).sum().item()\n",
    "                total += data.y.size(0)\n",
    "                \n",
    "                # Loss calculation\n",
    "                if args_namespace and args_namespace.baseline_mode == 4:\n",
    "                    # For GCOD evaluation, use L1 with u=0 as a proxy.\n",
    "                    # GCODLoss.compute_L1(self, logits, targets, u_params)\n",
    "                    u_eval_dummy = torch.zeros(data.y.size(0), device=device, dtype=torch.float)\n",
    "                    # If you trained u_values for validation set and want to use them:\n",
    "                    # batch_indices_eval = torch.tensor(data.original_idx, dtype=torch.long).to(device)\n",
    "                    # u_eval_dummy = u_values_global_eval[batch_indices_eval].clone().detach().to(device)\n",
    "\n",
    "                    loss_value = criterion.compute_L1(output, data.y, u_eval_dummy)\n",
    "                else:\n",
    "                    loss_value = criterion(output, data.y) # Standard call for other losses\n",
    "                total_loss_val += loss_value.item()\n",
    "            else:\n",
    "                predictions_list.extend(pred.cpu().numpy()) # Renamed\n",
    "\n",
    "    if calculate_accuracy:\n",
    "        accuracy = correct / total if total > 0 else 0.0\n",
    "        avg_loss = total_loss_val / len(data_loader) if len(data_loader) > 0 else 0.0\n",
    "        return avg_loss, accuracy\n",
    "    return predictions_list # Renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.953707Z",
     "iopub.status.busy": "2025-05-30T15:34:04.953543Z",
     "iopub.status.idle": "2025-05-30T15:34:04.964161Z",
     "shell.execute_reply": "2025-05-30T15:34:04.963582Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.953694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_progress(train_losses, train_accuracies, val_losses, val_accuracies, output_dir):\n",
    "    \"\"\"\n",
    "    Plot training and validation progress over epochs.\n",
    "    \n",
    "    Args:\n",
    "        train_losses: List of training losses per epoch\n",
    "        train_accuracies: List of training accuracies per epoch  \n",
    "        val_losses: List of validation losses per epoch\n",
    "        val_accuracies: List of validation accuracies per epoch\n",
    "        output_dir: Directory to save the plot\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue', marker='o')\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\", color='red', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot accuracies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green', marker='o')\n",
    "    plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\", color='orange', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save plot\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.965356Z",
     "iopub.status.busy": "2025-05-30T15:34:04.964899Z",
     "iopub.status.idle": "2025-05-30T15:34:04.979688Z",
     "shell.execute_reply": "2025-05-30T15:34:04.978957Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.965337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, test_path):\n",
    "    script_dir = os.getcwd() \n",
    "    submission_folder = os.path.join(script_dir, \"submission\")\n",
    "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "    \n",
    "    os.makedirs(submission_folder, exist_ok=True)\n",
    "    \n",
    "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
    "    \n",
    "    test_graph_ids = list(range(len(predictions)))\n",
    "    output_df = pd.DataFrame({\n",
    "        \"id\": test_graph_ids,\n",
    "        \"pred\": predictions\n",
    "    })\n",
    "    \n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.980627Z",
     "iopub.status.busy": "2025-05-30T15:34:04.980369Z",
     "iopub.status.idle": "2025-05-30T15:34:04.994820Z",
     "shell.execute_reply": "2025-05-30T15:34:04.994256Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.980587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_user_input(prompt, default=None, required=False, type_cast=str):\n",
    "\n",
    "    while True:\n",
    "        user_input = input(f\"{prompt} [{default}]: \")\n",
    "        \n",
    "        if user_input == \"\" and required:\n",
    "            print(\"This field is required. Please enter a value.\")\n",
    "            continue\n",
    "        \n",
    "        if user_input == \"\" and default is not None:\n",
    "            return default\n",
    "        \n",
    "        if user_input == \"\" and not required:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            return type_cast(user_input)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid input. Please enter a valid {type_cast.__name__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:04.997001Z",
     "iopub.status.busy": "2025-05-30T15:34:04.996748Z",
     "iopub.status.idle": "2025-05-30T15:34:05.008062Z",
     "shell.execute_reply": "2025-05-30T15:34:05.007469Z",
     "shell.execute_reply.started": "2025-05-30T15:34:04.996986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    \"\"\"Set training configuration directly\"\"\"\n",
    "    args = {\n",
    "        # Dataset selection\n",
    "        'dataset': 'D',  # Choose: A, B, C, D\n",
    "        'train_mode': 1,  # 1=single dataset, 2=all datasets\n",
    "        \n",
    "        # Model config\n",
    "        #'gnn': 'gin',  # gin, gin-virtual, gcn, gcn-virtual\n",
    "        'num_layer': 3,\n",
    "        'emb_dim': 218,\n",
    "        'drop_ratio': 0.7,   # Dropout ratio\n",
    "        'virtual_node': True, # True to use virtual node, False otherwise\n",
    "        'residual': True,    # True to use residual connections, False otherwise\n",
    "        'JK': \"last\",         # Jumping Knowledge: \"last\", \"sum\", \"cat\"\n",
    "        'graph_pooling': \"mean\", # \"sum\", \"mean\", \"max\", \"attention\", \"set2set\"\n",
    "        'edge_drop_ratio' : 0.3,\n",
    "        'batch_norm' : True,\n",
    "        'layer_norm': False,\n",
    "        \n",
    "        # Training config\n",
    "        'batch_size': 64,\n",
    "        'epochs': 250,\n",
    "        'baseline_mode': 4,  # 1=CE, 2=Noisy CE, 3 GCE, 4 GCOD\n",
    "        'noise_prob': 0.2,\n",
    "        'gce_q' : 0.4,\n",
    "        'initial_lr' : 5e-3,\n",
    "\n",
    "        # Early stopping config\n",
    "        'early_stopping': True,  # Enable/disable early stopping\n",
    "        'patience': 25,\n",
    "        \n",
    "        # GCOD Loss Hyperparameters\n",
    "        'gcod_lambda_p': 2.0,    # Weight for prediction penalty in GCOD\n",
    "        'gcod_T_u': 15,           # Number of optimization iterations for u in GCOD\n",
    "        'gcod_lr_u': 0.1,       # Learning rate for optimizing u in GCOD\n",
    "\n",
    "        \n",
    "\n",
    "        # Lr scheduler config =================================================================================================================\n",
    "        'use_scheduler' : True,\n",
    "        'scheduler_type': 'ReduceLROnPlateau',  # Options: 'StepLR', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'ExponentialLR', 'OneCycleLR'\n",
    "\n",
    "        # StepLR parameters\n",
    "        'step_size': 30,      # Period of learning rate decay for StepLR\n",
    "        'gamma': 0.5,         # Multiplicative factor of learning rate decay\n",
    "        \n",
    "        # ReduceLROnPlateau parameters\n",
    "        'patience_lr': 10,    # Number of epochs with no improvement after which LR will be reduced\n",
    "        'factor': 0.5,        # Factor by which the learning rate will be reduced\n",
    "        'min_lr': 1e-7,       # Lower bound on the learning rate\n",
    "\n",
    "        \n",
    "        \n",
    "        # System config\n",
    "        'device': 0,\n",
    "        'num_checkpoints': 10\n",
    "    }\n",
    "    return argparse.Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:05.009028Z",
     "iopub.status.busy": "2025-05-30T15:34:05.008779Z",
     "iopub.status.idle": "2025-05-30T15:34:05.023373Z",
     "shell.execute_reply": "2025-05-30T15:34:05.022653Z",
     "shell.execute_reply.started": "2025-05-30T15:34:05.009009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def populate_args(args):\n",
    "    print(\"Arguments received:\")\n",
    "    for key, value in vars(args).items():\n",
    "        print(f\"{key}: {value}\")\n",
    "args = get_arguments()\n",
    "populate_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:05.024186Z",
     "iopub.status.busy": "2025-05-30T15:34:05.024031Z",
     "iopub.status.idle": "2025-05-30T15:34:05.034479Z",
     "shell.execute_reply": "2025-05-30T15:34:05.033843Z",
     "shell.execute_reply.started": "2025-05-30T15:34:05.024174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NoisyCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, p_noisy):\n",
    "        super().__init__()\n",
    "        self.p = p_noisy\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        losses = self.ce(logits, targets)\n",
    "        weights = (1 - self.p) + self.p * (1 - torch.nn.functional.one_hot(targets, num_classes=logits.size(1)).float().sum(dim=1))\n",
    "        return (losses * weights).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCOD vecchia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:05.035499Z",
     "iopub.status.busy": "2025-05-30T15:34:05.035286Z",
     "iopub.status.idle": "2025-05-30T15:34:05.055858Z",
     "shell.execute_reply": "2025-05-30T15:34:05.055149Z",
     "shell.execute_reply.started": "2025-05-30T15:34:05.035466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCODLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Centroid Outlier Discounting (GCOD) Loss Function\n",
    "    Based on the NCOD method adapted for graph classification.\n",
    "    The model parameters (theta) are updated using L1 + L3.\n",
    "    The sample-specific parameters (u) are updated using L2.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, alpha_train=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of classes.\n",
    "            alpha_train (float): Corresponds to lambda_p in args, coefficient for the\n",
    "                                 feedback term in L1.\n",
    "        \"\"\"\n",
    "        super(GCODLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.alpha_train = alpha_train\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none') # for per-sample CE\n",
    "\n",
    "    def _ensure_u_shape(self, u_params, batch_size, target_ndim):\n",
    "        \"\"\"Helper to ensure u_params has the correct shape for operations.\"\"\"\n",
    "        if u_params.shape[0] != batch_size:\n",
    "            raise ValueError(f\"u_params batch dimension {u_params.shape[0]} does not match expected batch_size {batch_size}\")\n",
    "\n",
    "        if target_ndim == 1: # Expected shape [batch_size]\n",
    "            return u_params.squeeze() if u_params.ndim > 1 else u_params\n",
    "        elif target_ndim == 2: # Expected shape [batch_size, 1]\n",
    "            return u_params.unsqueeze(1) if u_params.ndim == 1 else u_params\n",
    "        return u_params\n",
    "\n",
    "\n",
    "    def compute_L1(self, logits, targets, u_params):\n",
    "        \"\"\"\n",
    "        Computes L1 = CE(f_θ(Z_B)) + α_train * u_B * (y_B ⋅ ỹ_B)\n",
    "        Args:\n",
    "            logits (Tensor): Model output logits, shape [batch_size, num_classes].\n",
    "            targets (Tensor): Ground truth labels, shape [batch_size].\n",
    "            u_params (Tensor): Per-sample u values for the batch, shape [batch_size] or [batch_size, 1].\n",
    "        Returns:\n",
    "            Tensor: Scalar L1 loss for the batch.\n",
    "        \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        if batch_size == 0:\n",
    "            # Corrected line:\n",
    "            return torch.tensor(0.0, device=logits.device, requires_grad=logits.requires_grad)\n",
    "\n",
    "        y_onehot = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "        y_soft = F.softmax(logits, dim=1)\n",
    "\n",
    "        ce_loss_values = self.ce_loss(logits, targets) # Shape: [batch_size]\n",
    "\n",
    "        current_u_params = self._ensure_u_shape(u_params, batch_size, target_ndim=1)\n",
    "\n",
    "        feedback_term_values = self.alpha_train * current_u_params * (y_onehot * y_soft).sum(dim=1) # Shape: [batch_size]\n",
    "\n",
    "        L1 = ce_loss_values + feedback_term_values\n",
    "        return L1.mean()\n",
    "\n",
    "    def compute_L2(self, logits, targets, u_params):\n",
    "        \"\"\"\n",
    "        Computes L2 = (1/|C|) * ||ỹ_B + u_B * y_B - y_B||²\n",
    "        Args:\n",
    "            logits (Tensor): Model output logits, shape [batch_size, num_classes].\n",
    "            targets (Tensor): Ground truth labels, shape [batch_size].\n",
    "            u_params (Tensor): Per-sample u values for the batch, shape [batch_size] or [batch_size, 1].\n",
    "        Returns:\n",
    "            Tensor: Scalar L2 loss for the batch.\n",
    "        \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        if batch_size == 0:\n",
    "            # Corrected line:\n",
    "            return torch.tensor(0.0, device=logits.device, requires_grad=logits.requires_grad)\n",
    "\n",
    "        y_onehot = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "        y_soft = F.softmax(logits, dim=1)\n",
    "\n",
    "        current_u_params_unsqueezed = self._ensure_u_shape(u_params, batch_size, target_ndim=2)\n",
    "\n",
    "        term = y_soft + current_u_params_unsqueezed * y_onehot - y_onehot # Shape: [batch_size, num_classes]\n",
    "\n",
    "        # L2 norm squared of the matrix 'term', then scaled\n",
    "        L2 = (1.0 / self.num_classes) * torch.norm(term, p='fro').pow(2) # Frobenius norm for matrix\n",
    "        return L2\n",
    "\n",
    "    def compute_L3(self, logits, targets, u_params, l3_coeff):\n",
    "        \"\"\"\n",
    "        Computes L3 = l3_coeff * D_KL(L || σ(-log(u_B)))\n",
    "                     where l3_coeff = (1 - training_accuracy)\n",
    "                     and L = log(σ(logit_true_class)) are log-probabilities\n",
    "                     and σ(-log(u_B)) are probabilities\n",
    "        Args:\n",
    "            logits (Tensor): Model output logits, shape [batch_size, num_classes].\n",
    "            targets (Tensor): Ground truth labels, shape [batch_size].\n",
    "            u_params (Tensor): Per-sample u values for the batch, shape [batch_size] or [batch_size, 1].\n",
    "            l3_coeff (float): Coefficient for the KL divergence term, e.g., (1 - training_accuracy).\n",
    "        Returns:\n",
    "            Tensor: Scalar L3 loss for the batch.\n",
    "        \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        if batch_size == 0:\n",
    "            # Corrected line:\n",
    "            return torch.tensor(0.0, device=logits.device, requires_grad=logits.requires_grad)\n",
    "\n",
    "        y_onehot = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "\n",
    "        # Logit of the true class for each sample in the batch\n",
    "        diag_elements = (logits * y_onehot).sum(dim=1) # Shape: [batch_size]\n",
    "\n",
    "        # L_log_probs = log(sigma(true_class_logit)) which are log-probabilities\n",
    "        L_log_probs = F.logsigmoid(diag_elements) # Shape: [batch_size]\n",
    "\n",
    "        current_u_params = self._ensure_u_shape(u_params, batch_size, target_ndim=1)\n",
    "\n",
    "        # target_probs_for_kl = sigma(-log(u_B)) which are probabilities\n",
    "        target_probs_for_kl = torch.sigmoid(-torch.log(current_u_params + 1e-8)) # Shape: [batch_size]\n",
    "\n",
    "        # F.kl_div expects input (L_log_probs) as log-probabilities and target (target_probs_for_kl) as probabilities.\n",
    "        # reduction='mean' averages the loss over all elements in the batch.\n",
    "        # log_target=False means target_probs_for_kl are probabilities, not log-probabilities.\n",
    "        kl_div = F.kl_div(L_log_probs, target_probs_for_kl, reduction='mean', log_target=False)\n",
    "\n",
    "        L3 = l3_coeff * kl_div\n",
    "        return L3\n",
    "\n",
    "    def forward(self, logits, targets, u_params, training_accuracy):\n",
    "        \"\"\"\n",
    "        Calculates the GCOD loss components.\n",
    "        The main loss for model (theta) update is L1 + L3.\n",
    "        L2 is primarily used for updating u_params (called separately).\n",
    "        Args:\n",
    "            logits (Tensor): Model output logits.\n",
    "            targets (Tensor): Ground truth labels.\n",
    "            u_params (Tensor): Per-sample u values for the batch.\n",
    "            training_accuracy (float): The actual training accuracy (value between 0 and 1)\n",
    "                                     for the current batch or epoch.\n",
    "        Returns:\n",
    "            tuple: (total_loss_for_theta, L1, L2, L3)\n",
    "                   total_loss_for_theta = L1 + L3\n",
    "        \"\"\"\n",
    "        calculated_L1 = self.compute_L1(logits, targets, u_params)\n",
    "        # L2 is calculated here mainly for complete reporting if needed,\n",
    "        # but the train loop will call compute_L2 separately for u-optimization.\n",
    "        calculated_L2 = self.compute_L2(logits, targets, u_params)\n",
    "\n",
    "        l3_coefficient = (1.0 - training_accuracy) # As per GCOD paper (1 - alpha_train where alpha_train is accuracy)\n",
    "        calculated_L3 = self.compute_L3(logits, targets, u_params, l3_coefficient)\n",
    "\n",
    "        total_loss_for_theta = calculated_L1 + calculated_L3\n",
    "\n",
    "        return total_loss_for_theta, calculated_L1, calculated_L2, calculated_L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:05.072179Z",
     "iopub.status.busy": "2025-05-30T15:34:05.071991Z",
     "iopub.status.idle": "2025-05-30T15:34:05.089565Z",
     "shell.execute_reply": "2025-05-30T15:34:05.088843Z",
     "shell.execute_reply.started": "2025-05-30T15:34:05.072163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Enhanced GNN Training Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get configuration\n",
    "args = get_arguments()\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:05.090762Z",
     "iopub.status.busy": "2025-05-30T15:34:05.090316Z",
     "iopub.status.idle": "2025-05-30T15:34:29.205231Z",
     "shell.execute_reply": "2025-05-30T15:34:29.204558Z",
     "shell.execute_reply.started": "2025-05-30T15:34:05.090739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\\\n\" + \"=\"*40)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "base_path = '/kaggle/input/deep-dataset-preprocessed/processed_data_separate'\n",
    "\n",
    "# Prepare training/validation data based on mode\n",
    "if args.train_mode == 1:\n",
    "    # Single dataset mode\n",
    "    dataset_name = args.dataset\n",
    "    \n",
    "    loaded_train_graphs = torch.load(f'{base_path}/{dataset_name}_train_graphs.pt', weights_only=False)\n",
    "    train_dataset_with_indices = []\n",
    "    for i, data_item in enumerate(loaded_train_graphs):\n",
    "        data_item = add_zeros(data_item)\n",
    "        data_item.original_idx = i # Store original index\n",
    "        train_dataset_with_indices.append(data_item)\n",
    "    train_dataset = train_dataset_with_indices\n",
    "    \n",
    "    loaded_val_graphs = torch.load(f'{base_path}/{dataset_name}_val_graphs.pt', weights_only=False)\n",
    "    val_dataset_with_indices = []\n",
    "    for i, data_item in enumerate(loaded_val_graphs):\n",
    "        data_item = add_zeros(data_item)\n",
    "        data_item.original_idx = i # Store original index for val set too if needed by u_params in eval\n",
    "        val_dataset_with_indices.append(data_item)\n",
    "    val_dataset = val_dataset_with_indices\n",
    "    \n",
    "    # Test dataset usually doesn't need original_idx for u_params update\n",
    "    test_dataset = torch.load(f'{base_path}/{dataset_name}_test_graphs.pt', weights_only=False)\n",
    "    test_dataset = [add_zeros(data) for data in test_dataset] # original_idx not strictly needed for test\n",
    "    \n",
    "    print(f\"Using single dataset: {dataset_name}\")\n",
    "else:\n",
    "    # All datasets mode\n",
    "    train_dataset_with_indices = []\n",
    "    val_dataset_with_indices = []\n",
    "    current_train_idx = 0\n",
    "    current_val_idx = 0\n",
    "\n",
    "    for ds_name in ['A', 'B', 'C', 'D']:\n",
    "        loaded_train_ds = torch.load(f'{base_path}/{ds_name}_train_graphs.pt', weights_only=False)\n",
    "        for data_item in loaded_train_ds:\n",
    "            data_item = add_zeros(data_item)\n",
    "            data_item.original_idx = current_train_idx\n",
    "            train_dataset_with_indices.append(data_item)\n",
    "            current_train_idx += 1\n",
    "            \n",
    "        loaded_val_ds = torch.load(f'{base_path}/{ds_name}_val_graphs.pt', weights_only=False)\n",
    "        for data_item in loaded_val_ds:\n",
    "            data_item = add_zeros(data_item)\n",
    "            data_item.original_idx = current_val_idx\n",
    "            val_dataset_with_indices.append(data_item)\n",
    "            current_val_idx +=1\n",
    "            \n",
    "    train_dataset = train_dataset_with_indices\n",
    "    val_dataset = val_dataset_with_indices\n",
    "    \n",
    "    test_dataset = torch.load(f'{base_path}/{args.dataset}_test_graphs.pt', weights_only=False)\n",
    "    test_dataset = [add_zeros(data) for data in test_dataset] # original_idx not strictly needed for test\n",
    "    print(\"Using all datasets for training\")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scheduler setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:29.206170Z",
     "iopub.status.busy": "2025-05-30T15:34:29.205967Z",
     "iopub.status.idle": "2025-05-30T15:34:29.426942Z",
     "shell.execute_reply": "2025-05-30T15:34:29.426062Z",
     "shell.execute_reply.started": "2025-05-30T15:34:29.206153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"MODEL SETUP\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Initialize model\n",
    "model = GNN(num_class=6, # Assuming 6 classes based on original notebook\n",
    "            num_layer=args.num_layer,\n",
    "            emb_dim=args.emb_dim,\n",
    "            drop_ratio=args.drop_ratio,\n",
    "            virtual_node=args.virtual_node,\n",
    "            residual=args.residual,\n",
    "            JK=args.JK,\n",
    "            graph_pooling=args.graph_pooling,\n",
    "            edge_drop_ratio = args.edge_drop_ratio,\n",
    "            batch_norm=args.batch_norm\n",
    "           )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Setup optimizer and loss\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "if args.baseline_mode == 2:\n",
    "    criterion = NoisyCrossEntropyLoss(args.noise_prob)\n",
    "    print(f\"Using Noisy Cross Entropy Loss (p={args.noise_prob})\")\n",
    "elif args.baseline_mode == 3: # <--- ADD THIS BLOCK FOR GCE\n",
    "    criterion = GeneralizedCrossEntropyLoss(q=args.gce_q)\n",
    "    print(f\"Using Generalized Cross Entropy (GCE) Loss (q={args.gce_q})\")\n",
    "elif args.baseline_mode == 4: # GCOD Loss\n",
    "    criterion = GCODLoss(\n",
    "        num_classes=6, # Assuming 6 classes\n",
    "        alpha_train=args.gcod_lambda_p # Map gcod_lambda_p to alpha_train\n",
    "    )\n",
    "    # Updated print statement to reflect lambda_r is used\n",
    "    print(f\"Using GCOD Loss. Effective alpha_train (lambda_p for L1)={args.gcod_lambda_p}, \"\n",
    "          f\"T_u={args.gcod_T_u}, lr_u={args.gcod_lr_u}\")\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    print(\"Using standard Cross Entropy Loss\")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Setup logging and checkpoints\n",
    "#exp_name = f\"{args.gnn}_dataset{args.dataset}_mode{args.train_mode}\"\n",
    "exp_name = f\"gin_dataset{args.dataset}_mode{args.train_mode}\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "checkpoints_dir = os.path.join(\"checkpoints\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "log_file = os.path.join(logs_dir, \"training.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "#best_model_path = os.path.join(checkpoints_dir, \"best_model.pth\")\n",
    "best_model_path = '/kaggle/working/checkpoints/best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:29.428130Z",
     "iopub.status.busy": "2025-05-30T15:34:29.427885Z",
     "iopub.status.idle": "2025-05-30T15:34:29.435859Z",
     "shell.execute_reply": "2025-05-30T15:34:29.434984Z",
     "shell.execute_reply.started": "2025-05-30T15:34:29.428112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler Setup\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"SCHEDULER SETUP\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Update optimizer with initial learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.initial_lr)\n",
    "\n",
    "scheduler = None\n",
    "if args.use_scheduler:\n",
    "    if args.scheduler_type == 'StepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, \n",
    "            step_size=args.step_size, \n",
    "            gamma=args.gamma\n",
    "        )\n",
    "        print(f\"Using StepLR scheduler: step_size={args.step_size}, gamma={args.gamma}\")\n",
    "        \n",
    "    elif args.scheduler_type == 'ReduceLROnPlateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='max',  # We want to reduce LR when validation loss stops decreasing\n",
    "            factor=args.factor,\n",
    "            patience=args.patience_lr,\n",
    "            min_lr=args.min_lr,\n",
    "        )\n",
    "        print(f\"Using ReduceLROnPlateau scheduler: factor={args.factor}, patience={args.patience_lr}, min_lr={args.min_lr}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Unknown scheduler type: {args.scheduler_type}. No scheduler will be used.\")\n",
    "        args.use_scheduler = False\n",
    "else:\n",
    "    print(\"No learning rate scheduler will be used.\")\n",
    "\n",
    "print(f\"Initial learning rate: {args.initial_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:34:29.437057Z",
     "iopub.status.busy": "2025-05-30T15:34:29.436762Z",
     "iopub.status.idle": "2025-05-30T15:57:21.884752Z",
     "shell.execute_reply": "2025-05-30T15:57:21.883977Z",
     "shell.execute_reply.started": "2025-05-30T15:34:29.437035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\\\n\" + \"=\"*40)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Initialize u_values_for_train here, after train_dataset is fully formed (from Step 1)\n",
    "u_values_for_train = None\n",
    "if args.baseline_mode == 4:\n",
    "    if 'train_dataset' in locals() and len(train_dataset) > 0 : # Check if train_dataset exists\n",
    "        u_values_for_train = torch.zeros(len(train_dataset), device=device, requires_grad=False) # on main device\n",
    "        print(f\"Initialized u_values_for_train for GCOD with size: {u_values_for_train.size()}\")\n",
    "    else:\n",
    "        print(\"Warning: train_dataset not found or empty when trying to initialize u_values_for_train for GCOD.\")\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "train_losses_list = [] # Renamed\n",
    "train_accuracies_list = [] # Renamed\n",
    "val_losses_list = [] # Renamed\n",
    "val_accuracies_list = [] # Renamed\n",
    "learning_rates = []\n",
    "\n",
    "# Early stopping variables\n",
    "if args.early_stopping:\n",
    "    epochs_without_improvement = 0\n",
    "    print(f\"Early stopping enabled with patience: {args.patience}\")\n",
    "else:\n",
    "    print(\"Early stopping disabled\")\n",
    "\n",
    "# Calculate checkpoint intervals\n",
    "if args.num_checkpoints > 1:\n",
    "    checkpoint_intervals = [int((i + 1) * args.epochs / args.num_checkpoints) \n",
    "                          for i in range(args.num_checkpoints)]\n",
    "else:\n",
    "    checkpoint_intervals = [args.epochs]\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(f\"\\\\nEpoch {epoch + 1}/{args.epochs}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Get current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train(\n",
    "        train_loader, model, optimizer, criterion, device,\n",
    "        save_checkpoints=(epoch + 1 in checkpoint_intervals), # This was inside train, moved out\n",
    "        checkpoint_path=os.path.join(checkpoints_dir, \"checkpoint\"),\n",
    "        current_epoch=epoch,\n",
    "        args_namespace=args, # Pass the whole args namespace\n",
    "        u_values_global=u_values_for_train, # Pass global u_values\n",
    "        current_baseline_mode=args.baseline_mode, # Pass baseline_mode\n",
    "        scheduler=args.scheduler_type\n",
    "    )\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc = evaluate(\n",
    "        val_loader, model, criterion, device, calculate_accuracy=True,\n",
    "        args_namespace=args, # Pass args for baseline_mode check\n",
    "        u_values_global_eval=None # Pass u_values_for_val if you implement using them, else dummy zeros are used\n",
    "    )    \n",
    "    # Log results\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    \n",
    "    logging.info(f\"Epoch {epoch + 1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "                f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}, LR={current_lr:.2e}\")\n",
    "    \n",
    "    # Store metrics (existing code using new list names)\n",
    "    train_losses_list.append(train_loss)\n",
    "    train_accuracies_list.append(train_acc)\n",
    "    val_losses_list.append(val_loss)\n",
    "    val_accuracies_list.append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"★ New best model saved! Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "        # Reset early stopping counter\n",
    "        if args.early_stopping:\n",
    "            epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # No improvement\n",
    "        if args.early_stopping:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "            \n",
    "            # Check if we should stop early\n",
    "            if epochs_without_improvement >= args.patience:\n",
    "                print(f\"\\nEarly stopping triggered! No improvement for {args.patience} epochs.\")\n",
    "                print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "                break\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    if scheduler is not None:\n",
    "        if args.scheduler_type == 'ReduceLROnPlateau':\n",
    "            # ReduceLROnPlateau needs the metric to monitor\n",
    "            scheduler.step(val_acc)\n",
    "        elif args.scheduler_type == 'OneCycleLR':\n",
    "            # OneCycleLR steps every batch, not every epoch\n",
    "            # This is handled in the training function\n",
    "            pass\n",
    "        else:\n",
    "            # Other schedulers step every epoch\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Check if learning rate changed\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr != current_lr:\n",
    "            print(f\"Learning rate changed: {current_lr:.2e} → {new_lr:.2e}\")\n",
    "    \n",
    "print(f\"\\nBest validation accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:57:21.886077Z",
     "iopub.status.busy": "2025-05-30T15:57:21.885597Z",
     "iopub.status.idle": "2025-05-30T15:57:22.587543Z",
     "shell.execute_reply": "2025-05-30T15:57:22.586770Z",
     "shell.execute_reply.started": "2025-05-30T15:57:21.886050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_training_progress(train_losses_list, train_accuracies_list, val_losses_list, val_accuracies_list, logs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T15:57:22.588447Z",
     "iopub.status.busy": "2025-05-30T15:57:22.588258Z",
     "iopub.status.idle": "2025-05-30T15:57:24.485075Z",
     "shell.execute_reply": "2025-05-30T15:57:24.484264Z",
     "shell.execute_reply.started": "2025-05-30T15:57:22.588432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"TESTING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Load best model and make predictions\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "print(f\"Loaded best model from: {best_model_path}\")\n",
    "\n",
    "#predictions = evaluate(test_loader, model, criterion, device, calculate_accuracy=False)\n",
    "\n",
    "# Save predictions\n",
    "predictions = evaluate(\n",
    "    test_loader, model, criterion, device, calculate_accuracy=False,\n",
    "    args_namespace=args, # For consistency, though not used if calculate_accuracy=False and GCOD loss not computed\n",
    "    u_values_global_eval=None # Not relevant for test set predictions without loss\n",
    ")\n",
    "\n",
    "# Save predictions\n",
    "save_predictions(predictions,f\"/kaggle/working/submission/testset_{args.dataset}.json\")\n",
    "\n",
    "# Cleanup for memory\n",
    "del train_dataset, val_dataset, test_dataset\n",
    "del train_loader, val_loader, test_loader\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "print(f\"Predictions saved for dataset {args.dataset}\")\n",
    "print(f\"Logs and plots saved in: {logs_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7519186,
     "sourceId": 11958675,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7519473,
     "sourceId": 11998952,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
